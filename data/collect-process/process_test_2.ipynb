{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54244f8b",
   "metadata": {},
   "source": [
    "I processed the data I scraped from ifcb so we can do the classification using image features.\n",
    "- Now trying to figure how to use ifcb and enviromental features I collected.\n",
    "-   The issue is that env variables are binned by day. \n",
    "\n",
    "So I kind of messed up collecting the data as I didn't get some important metadata like:\n",
    "```\n",
    "Triggers: 919\n",
    "Images: 930\n",
    "Triggers / s: 0.765\n",
    "Volume Analyzed: 4.687 ml\n",
    "ROIs / ml: 198.432\n",
    "Size: 6.86 MB\n",
    "Latitude: 32.86671\n",
    "Longitude: -117.25587\n",
    "```\n",
    "Which is seemingly only available in that little side bar and not in a file (?)\n",
    "\n",
    "- From my minimal research and knowledge it seems like you're supposed to do cells/mL as absolute abundance but I didn't get that data so..\n",
    "- supposedly you can use the amount of L.poly / ROI in a sample as relative abundance since it's a ratio\n",
    "    - something somethign fraction of ROI's that belong to a taxon.. \n",
    "- From scrolling through the bins, it seems the average amount collected in 4.5ml or around there so we just use that as the sampled amount..\n",
    "\n",
    "So essentially what I am doing in this notebook is for each ifcb bin getting:\n",
    "```\n",
    "date\n",
    "Lpoly_per_mL\n",
    "roiCount\n",
    "features...\n",
    "```\n",
    "\n",
    "Then bin by day which will give the daily mean of L. Polyedra per mL sampled\n",
    "- Also since this is a relatively rare algae, and the sample is pretty small the value for L. Polyedra will be small like .05 or smaller\n",
    "- that's why relative abundance doesn't really work for this...\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe2820d",
   "metadata": {},
   "source": [
    "One thing that I am confused about is whether to use thresholds to determine if the taxa is present or not.\n",
    "- like say 'A >.8'\n",
    "\n",
    "my AI chatbot of choice suggested using the sum of probabilies \n",
    "- This is because autoclass calcuates the percent confidence (prb) of it being the taxa\n",
    "- so supposedly when summing probabilties, you get the expected value contribution of that particle\n",
    "    - which is linearity of expectation \n",
    "\n",
    "I need to review statistics lmao. I'm so bad at this.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2984f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "s = datetime.now()\n",
    "\n",
    "base_path = \"./ifcb_downloads/\"\n",
    "burger = Path(base_path) # used for iterating months I'm kinda hungry\n",
    "out_dir = Path(\"./processed/\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def read_hdr(path: Path) -> dict:\n",
    "    return { k.strip(): v.strip()\n",
    "            for line in path.read_text().splitlines()\n",
    "            if \":\" in line\n",
    "            for k, v in [line.split(\":\", 1)] }\n",
    "samples = []\n",
    "# iterate through each month directory\n",
    "for month_dir in sorted(burger.iterdir()):\n",
    "    path = base_path + month_dir.name + \"/\"\n",
    "    print(f\"Processing files in {path}... {(datetime.now()- s).total_seconds()}s\")\n",
    "    \n",
    "    # for each hdr file in month folder get date and find matching files (with date)\n",
    "    for files in glob.glob(path + '*.hdr'):\n",
    "        timestamp = os.path.basename(files).split('_')[0].lstrip('D')\n",
    "        date = timestamp.split('T')[0]\n",
    "        # read class scores file and extract relevant columns\n",
    "        for match in glob.glob(os.path.join(path, f\"*{timestamp}*\")):\n",
    "            if match.endswith('.csv'):\n",
    "                if \"_features\" in match:\n",
    "                    try:\n",
    "                        features = pd.read_csv(Path(match))\n",
    "                        features.drop(columns=['roi_number'], inplace=True)\n",
    "                    except pd.errors.EmptyDataError:\n",
    "                        features = None\n",
    "                        print(f\"Features file is empty for date {timestamp}\")\n",
    "                else:\n",
    "                    try:\n",
    "                        class_scores = pd.read_csv(Path(match), usecols=['pid', 'Lingulodinium_polyedra'])\n",
    "                    except pd.errors.EmptyDataError:\n",
    "                        class_scores = None\n",
    "                        print(f\"Class scores file is empty for date {timestamp}\")\n",
    "            elif match.endswith('hdr'):\n",
    "                hdr = read_hdr(Path(match))\n",
    "                roi_count = float(hdr[\"roiCount\"])\n",
    "        \n",
    "        # if both files were read successfully, calculate weighted average\n",
    "        if isinstance(features, pd.DataFrame) and isinstance(class_scores, pd.DataFrame):\n",
    "            weights = class_scores[\"Lingulodinium_polyedra\"]\n",
    "            weighted_means = (features.multiply(weights, axis=0).sum()/ weights.sum())\n",
    "            sample_row = {\n",
    "                \"date\": date,\n",
    "                \"roiCount\": roi_count,\n",
    "                \"Lpoly_count\": weights.sum(),\n",
    "                \"Lpoly_ml\": weights.sum() / 4.5 }\n",
    "            for col, val in weighted_means.items():\n",
    "                sample_row[col] = val\n",
    "            samples.append(sample_row)\n",
    "\n",
    "samples_df = pd.DataFrame(samples)\n",
    "daily = (samples_df.groupby(\"date\").mean().reset_index())\n",
    "out_file = out_dir / \"processed.csv\"\n",
    "daily.to_csv(out_file, index=False)\n",
    "print(f\"Processing complete in {(datetime.now()- s).total_seconds()}s yay\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
