{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54244f8b",
   "metadata": {},
   "source": [
    "I processed the data I scraped from ifcb so we can do the classification using image features.\n",
    "- Now trying to figure how to use ifcb and enviromental features I collected.\n",
    "-   The issue is that env variables are binned by day. \n",
    "\n",
    "So I kind of messed up collecting the data as I didn't get some important metadata like:\n",
    "```\n",
    "Triggers: 919\n",
    "Images: 930\n",
    "Triggers / s: 0.765\n",
    "Volume Analyzed: 4.687 ml\n",
    "ROIs / ml: 198.432\n",
    "Size: 6.86 MB\n",
    "Latitude: 32.86671\n",
    "Longitude: -117.25587\n",
    "```\n",
    "Which is seemingly only available in that little side bar and not in a file (?)\n",
    "\n",
    "- From my minimal research and knowledge it seems like you're supposed to do cells/mL as absolute abundance but I didn't get that data so..\n",
    "- supposedly you can use the amount of L.poly / ROI in a sample as relative abundance since it's a ratio\n",
    "    - something somethign fraction of ROI's that belong to a taxon.. \n",
    "\n",
    "So essentially what I am doing in this notebook is for each ifcb bin getting:\n",
    "```\n",
    "timestamp\n",
    "Lpoly_fraction\n",
    "roiCount\n",
    "```\n",
    "\n",
    "Then bin by day which will give the daily mean fraction of L. Polyedra\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe2820d",
   "metadata": {},
   "source": [
    "One thing that I am confused about is whether to use thresholds to determine if the taxa is present or not.\n",
    "- like say 'A >.8'\n",
    "\n",
    "my AI chatbot of choice suggested using the sum of probabilies \n",
    "- This is because autoclass calcuates the percent confidence (prb) of it being the taxa\n",
    "- so supposedly when summing probabilties, you get the expected value contribution of that particle\n",
    "    - which is linearity of expectation \n",
    "\n",
    "I need to review statistics lmao. I'm so bad at this.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e454f8",
   "metadata": {},
   "source": [
    "So with the data I have this is what needs to be done??\n",
    "- Image features(from ifcb) -> classification finding important image features..\n",
    "- Daily relative abundances -> compare with enviromental features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2984f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "s = datetime.now()\n",
    "\n",
    "base_path = \"./ifcb_downloads/\"\n",
    "burger = Path(base_path) # used for iterating months I'm kinda hungry\n",
    "out_dir = Path(\"./processed2/\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def read_hdr(path: Path) -> dict:\n",
    "    return { k.strip(): v.strip()\n",
    "            for line in path.read_text().splitlines()\n",
    "            if \":\" in line\n",
    "            for k, v in [line.split(\":\", 1)] }\n",
    "\n",
    "# iterate through each month directory\n",
    "for month_dir in sorted(burger.iterdir()):\n",
    "    path = base_path + month_dir.name + \"/\"\n",
    "    print(f\"Processing files in {path}... {(datetime.now()- s).total_seconds()}s\")\n",
    "    \n",
    "    # for each hdr file in month folder get date and find matching files (with date)\n",
    "    for files in glob.glob(path + '*.hdr'):\n",
    "        date = os.path.basename(files).split('_')[0].lstrip('D')\n",
    "        # read class scores file and extract relevant columns\n",
    "        for match in glob.glob(os.path.join(path, f\"*{date}*\")):\n",
    "            if match.endswith('.csv'):\n",
    "                if 'class_scores' in match:\n",
    "                    try:\n",
    "                        class_scores = pd.read_csv(Path(match), usecols=['pid', 'Lingulodinium_polyedra'])\n",
    "                        lpoly_fraction = (class_scores[\"Lingulodinium_polyedra\"].sum() / len(class_scores))\n",
    "                    except pd.errors.EmptyDataError:\n",
    "                        class_scores = pd.DataFrame()\n",
    "                        print(f\"Class scores file is empty for date {date}\")\n",
    "            elif match.endswith('hdr'):\n",
    "                hdr = read_hdr(Path(match))\n",
    "                roi_count = float(hdr[\"roiCount\"])\n",
    "\n",
    "print(f\"Processing complete in {(datetime.now()- s).total_seconds()}s yay\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
