{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0b42557",
   "metadata": {},
   "source": [
    "Trying beautiful soup as a web scraper\n",
    "\n",
    "The issue is that the page loads the links with javascript. and I guess soup gets the stuff before javascript loads idk\n",
    "\n",
    "so the new plan is use tampermonkey?? It definitely works.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60467bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://ifcb.caloos.org/bin?dataset=scripps-pier-ifcb-183&bin=D20250101T185049_IFCB183\"\n",
    "\n",
    "out_dir = Path(\"ifcb_downloads\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "tag = soup.find(\"a\", id=\"download-features\")\n",
    "print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70d1fa1",
   "metadata": {},
   "source": [
    "Trying Selenium now\n",
    "- https://github.com/oxylabs/Scraping-Dynamic-JavaScript-Ajax-Websites-With-BeautifulSoup\n",
    "\n",
    "^ This guide uses webdriver-manager\n",
    "- https://pypi.org/project/webdriver-manager/\n",
    "    - On my laptop (windows), I am using ungoogled chromium Version 137.0.7151.119 (Official Build, ungoogled-chromium) (64-bit)\n",
    "        - this one https://github.com/ungoogled-software/ungoogled-chromium/releases/tag/137.0.7151.119-1 (june 20, 2025 build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f3b6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromiumService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from webdriver_manager.core.os_manager import ChromeType\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "out_dir = Path(\"ifcb_downloads\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "base_url=\"https://ifcb.caloos.org\"\n",
    "start_url = \"https://ifcb.caloos.org/bin?dataset=scripps-pier-ifcb-183&bin=D20250101T185049_IFCB183\"\n",
    "url = start_url\n",
    "date = url.split(\"bin=\")[1].split(\"_\")[0][1:9]\n",
    "s = datetime.now()\n",
    "\n",
    "driver = webdriver.Chrome(service=ChromiumService(ChromeDriverManager(chrome_type=ChromeType.CHROMIUM).install()))\n",
    "\n",
    "while '20250103' not in url:  # download files until 2025-01-03 (testing)\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(2)  # wait for Js to load content\n",
    "    # wait up to 15 seconds, poll every 1 seconds\n",
    "    wait = WebDriverWait(driver, 15, poll_frequency=1)\n",
    "\n",
    "    def href_not_hash(driver):\n",
    "        el1 = driver.find_element(By.ID, \"download-hdr\")\n",
    "        href1 = el1.get_attribute(\"href\")\n",
    "        return \"hdr\" in href1\n",
    "    wait.until(href_not_hash)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    for file_id in [\"download-hdr\",\"download-features\",\"download-class-scores\"]:\n",
    "        tag = soup.find(\"a\", id=file_id)\n",
    "        file_url = base_url + tag[\"href\"]\n",
    "\n",
    "        filename = file_url.split(\"/\")[-1]\n",
    "        out_path = out_dir / filename\n",
    "\n",
    "        with requests.get(file_url, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            with open(out_path, \"wb\") as f:\n",
    "                for chunk in r.iter_content(8192):\n",
    "                    f.write(chunk)\n",
    "    \n",
    "    # physically click the \"Next Bin\" button\n",
    "    # there is some js shenanigans that prevents just getting the href\n",
    "    next_button = driver.find_element(By.ID, \"next-bin\")\n",
    "    driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "\n",
    "    # wait for URL to change\n",
    "    wait.until(lambda d: d.current_url != url)\n",
    "    new_date = driver.current_url.split(\"bin=\")[1].split(\"_\")[0][1:9]\n",
    "    if new_date != date: \n",
    "        print(f\"Downloaded data for: {date} in {(datetime.now()- s).total_seconds()} s\")\n",
    "        date = new_date\n",
    "    url = driver.current_url\n",
    "\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
